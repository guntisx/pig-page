
<!-- saved from url=(0026)https://guntisx.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>[MOTE]</title>

</head>

<body>
<h1>
	VPP-EM-FOTONIKA-2022/1-0001 Smart Materials, Photonics, Technologies and Engineering
Ecosystem [MOTE]
</h1>


	WP4 “ROBOTICS/IoT” is dedicated to three groups of technologies have been identified for their high added value capacity for industry needs: robotics, internet of things (IoT) and smart sensor systems, that are aimed at solving industry driven problems. In robotics there are two research subfields that require new solutions for more efficient robot use - making systems smarter and more perceptive of their environments and making systems control both easier and more efficient. 
<br>
4.1. In the first task we develop a framework for the perception and interpretation of complex scenes and voice commands, including SLAM (Simultaneous Localization and Mapping) to perfect the understanding of visual and audio information for use in robotics applications. To deploy robotic systems in dynamic environments, the scene must be perceived and interpreted accordingly, namely to reason about the objects in it, their properties and how to interact with them, to succeed in the given task. Combining perception with high-level instructions, we explore the potential of both parties in human and robot collaboration/interaction.
<br>
4.2. In the second task we develop and demonstrate a common framework enabling flexible multi-modal robot control in weakly structured environments and operations to ensure cooperative and emergent behaviour. While robots and robot-centric systems have been used for decades, a true autonomy and intelligent operation in its wider understanding still is very challenging including efficiency, safety, and cooperative operation. Autonomous robots, i.e., self-driving cars, operating collision-free in densely populated environments still require human-in-the-loop to set the goal and manually resolve pathologic situations. In this respect collaborative multi-modal robot management will be an important result of the project.

<br>

<a href="http://194.8.1.230:7788/"> Jupyter notebook server </a> --
<br>
<img src="./[MOTE]_files/9659273.jpeg" alt="Slave market in Rome">
	
	<br>
	<a href="https://guntisx.github.io/pythonindex.html"> PyScript example </a> --
		
			<br>
	<a href="http://194.8.1.232:7777/uploads/cryptominisat_web-master/"> WASM SAT solver </a> --
			<br>
	<a href="https://whisper.ggerganov.com/"> WASM Whisper </a> --		
			<br>
	<a href="http://194.8.1.230:5002/results"> Mongo Whisper </a> --	
							<br>
	<a href="http://87.110.211.231:10100/x:selmaproject:whisper_api:large-cpu-0.0.1:8000/docs"> SELMA DockerSpaces Whisper </a> --	
							<br>
	<a href="https://huggingface.co/docs/hub/spaces-sdks-docker"> HuggingFace DockerSpaces </a> --	



</body><style>#matter-popup-app {
  border: 0 !important;
  box-shadow: 0px 0px transparent;
  color-scheme: light !important;
  right: 0 !important;
  padding: 0 !important;
  pointer-events: none !important;
  position: fixed !important;
  opacity: 0 !important;
  top: 10px !important;
  transition: opacity 0.2s ease !important;
  user-select: none !important;
  height: 500px !important;
  width: 470px !important;
  z-index: 9007199254740991 !important;
}

#matter-popup-app[data-matter-active] {
  display: block !important;
}

#matter-popup-app[data-matter-hidden] {
  visibility: hidden !important;
  z-index: -1 !important;
}

#matter-popup-app[data-matter-active="true"] {
  pointer-events: auto !important;
  opacity: 1 !important;
  transition: opacity 0.2s ease !important;
}

@media print {
  #matter-popup-app, #matter-floating-iframe, #matter-modal-iframe {
    display: none !important;
  }
}

#matter-floating-iframe {
  border: 0 !important;
  box-shadow: 0px 0px transparent;
  color-scheme: light !important;

  height: 187px !important;
  position: absolute !important;
  z-index: 9007199254740991 !important;
  width: 350px !important;

  pointer-events: none !important;
  opacity: 0 !important;
  visibility: hidden;
}

#matter-floating-iframe[data-matter-active] {
  display: block !important;
}

#matter-floating-iframe[data-matter-active="true"] {
  pointer-events: auto !important;
  opacity: 1 !important;
  visibility: visible;
}

#matter-modal-iframe {
  border: 0 !important;
  display: none !important;
  z-index: 9007199254740991 !important;
}

#matter-modal-iframe[data-matter-active="true"] {
  display: block !important;
  height: 100vh;
  width: 100vw;
  position: fixed;
  top: 0;
  left: 0;
}

mark[data-annotation-id][data-open-web-highlight] {
  background: #fff8c6 !important;
  box-shadow: 0 0.195em 0 0 #fff8c6,0 calc(0.195em * -1) 0 0 #fff8c6 !important;
  font-weight: inherit;
  font-style: inherit;
}

mark[data-annotation-id][data-open-web-highlight][data-line-height-normal] {
  box-shadow: none !important;
}

mark[data-open-web-highlight][data-annotation-has-note] {
  text-decoration: underline;
  text-decoration-color: #ffd02a;
  text-decoration-thickness: 2.5px;
  text-decoration-skip-ink: none;
  text-underline-offset: 1px;
}

mark[data-open-web-highlight][data-annotation-has-note][data-line-height-normal] {
  text-decoration-thickness: 1px;
}</style><iframe id="matter-popup-app" src="./[MOTE]_files/index.html" data-matter-active="false" aria-hidden="true" style="display: none;"></iframe><iframe id="matter-floating-iframe" src="./[MOTE]_files/popover.html" style="display: none;"></iframe><iframe id="matter-modal-iframe" src="./[MOTE]_files/modal.html" style="display: none;"></iframe></html>